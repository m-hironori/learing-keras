{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_2値分類(IMDbレビュー).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOithsa8ykEWEPyBb+eD/Sr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-hironori/learing-keras/blob/master/2_2%E5%80%A4%E5%88%86%E9%A1%9E(IMDb%E3%83%AC%E3%83%93%E3%83%A5%E3%83%BC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQIQ3EDG0cYk",
        "colab_type": "code",
        "outputId": "df9d6c8e-c318-431a-ec57-ca4e7149fc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWyUWxbfiku0",
        "colab_type": "text"
      },
      "source": [
        "# 2値分類(IMDbレビュー)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPenJcRpL1my",
        "colab_type": "text"
      },
      "source": [
        "kerasによるモデル作成の基本として、2値分類の例をやってみましょう。\n",
        "今回は、[IMDb](https://www.imdb.com/)という映画レビューサイトのポジネガ分類をやってみましょう。\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ILIsH0jHB6",
        "colab_type": "text"
      },
      "source": [
        "## 問題設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3I_agcBjJpi",
        "colab_type": "text"
      },
      "source": [
        "まずは、問題設定を確認してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX489a_LlS9j",
        "colab_type": "text"
      },
      "source": [
        "### 問題設定の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNbzxWHJL6Ha",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "問題属性 | 問題内容\n",
        "--- | ---\n",
        "入力データ形式 | レビューテキスト（英語）\n",
        "予測すること | レビュー内容が、ポジティブ or ネガティブ\n",
        "評価指標 | accuracy\n",
        "評価方法 | ホールドアウト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Yuw5Nbjw2x",
        "colab_type": "text"
      },
      "source": [
        "レビューテキストを入力に、ポジティブかネガティブかを当てることが問題設定です。\n",
        "\n",
        "keras には、あらかじめこのデータセットが用意されていて、扱いやすいため、\n",
        "keras のテキストを使った例としてはよく使われます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59iE32MelPnV",
        "colab_type": "text"
      },
      "source": [
        "## データ準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONqBg_ITlaPq",
        "colab_type": "text"
      },
      "source": [
        "データを準備してみましょう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4OX7Vbqle_T",
        "colab_type": "text"
      },
      "source": [
        "### データ取得する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHwweTr4ljeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34e0d82e-47d3-47ff-9fbd-2a56a927dab2"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My5ZSB2jmJOO",
        "colab_type": "text"
      },
      "source": [
        "データロードの関数が用意されているので、これを呼ぶだけで、データ取得が終わります。\n",
        "\n",
        "ダウンロード後、num_words=10000で、出現頻度順上位10,000の単語のみをロードしています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln1ZnlGjnG5Z",
        "colab_type": "text"
      },
      "source": [
        "### 内容を確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDY5LVsTnKSO",
        "colab_type": "text"
      },
      "source": [
        "* テンソルで準備：データはテンソル ( Numpy でーたが扱いやすい ) として準備\n",
        "* 値を正規化：値は [ -1 , -1 ] や [ 0 , 1 ] ぐらいの値にスケーリングしておく\n",
        "* スケール合わせ：特徴量の値の範囲がことなったり、異なる種類のデータを使う場合は、スケールを合わせるためにデータを正規化する "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzEcmP7LnLXG",
        "colab_type": "text"
      },
      "source": [
        "基本的に、上記3点がデータ準備で必要なことです。テンソル準備、値を正規化、そしてスケールを合わせる。\n",
        "\n",
        "今回はテキストデータのみなので、スケール合わせは必要なさそうです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClSLxP83nw1C",
        "colab_type": "text"
      },
      "source": [
        "### データ型を確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfaE8Y1Qn0bs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "50555447-f3e9-49db-c2ee-7f4233d09643"
      },
      "source": [
        "print(\"\\tデータ型\")\n",
        "print(f\"訓練データ\\t{type(train_data)}\")\n",
        "print(f\"訓練ラベル\\t{type(train_labels)}\")\n",
        "print(f\"テストデータ\\t{type(test_data)}\")\n",
        "print(f\"テストラベル\\t{type(test_labels)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tデータ型\n",
            "訓練データ\t<class 'numpy.ndarray'>\n",
            "訓練ラベル\t<class 'numpy.ndarray'>\n",
            "テストデータ\t<class 'numpy.ndarray'>\n",
            "テストラベル\t<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsXPoTV4oFqH",
        "colab_type": "text"
      },
      "source": [
        "Numpy形式で用意されているので、今回もデータ型はこのままでよさそうです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_bw-MjoVGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fe4157a1-47d8-4a39-ee1f-32eeaa5421f7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"\\tデータサイズ\\t型\\t最大値\\t最小値\")\n",
        "print(f\"訓練データ\\t{train_data.shape}\\t{train_data.dtype}\\t{train_data.max()}\\t{train_data.min()}\")\n",
        "print(f\"訓練ラベル\\t{train_labels.shape}\\t{train_labels.dtype}\\t{train_labels.max()}\\t{train_labels.min()}\")\n",
        "print(f\"テストデータ\\t{test_data.shape}\\t{test_data.dtype}\\t{test_data.max()}\\t{test_data.min()}\")\n",
        "print(f\"テストラベル\\t{test_labels.shape}\\t{test_labels.dtype}\\t{test_labels.max()}\\t{test_labels.min()}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tデータサイズ\t型\t最大値\t最小値\n",
            "訓練データ\t(25000,)\tobject\t[1, 9995, 2, 7, 2208, 7335, 3135, 4173, 3783, 509, 1683, 4702, 2, 2, 6, 201, 7, 6415, 687, 2, 2, 7, 6387, 548, 139, 7583, 295, 34, 4485, 5302, 2, 2, 2, 7, 2, 2, 146, 24, 1017, 2282, 133, 21, 4, 1591, 3113, 786, 2, 16, 125, 4, 2, 9790, 2039, 137, 267, 2, 5, 2, 120, 2024, 980, 2, 1248, 5666, 727, 1405, 6879, 1060, 6442, 18, 2, 1461, 2, 1883, 445, 109, 5369, 3696, 33, 236, 786, 5580, 7994, 8, 2, 2, 103, 2, 98, 11, 2, 1461, 24, 66, 351, 1461, 165, 116, 17, 2545, 18, 6717, 8694, 5514, 980, 2545, 165, 734, 18, 2311, 52, 84, 157, 18, 7232, 11, 661, 8, 607, 3531, 223, 1066, 445, 9236, 996, 8, 2898, 4931, 8, 5526, 8316, 7880, 154, 378, 459, 18, 6942, 632, 5, 79, 2024, 18, 68, 4918, 813, 2456, 2, 17, 840, 4807, 3854, 23, 136, 159, 5770, 852, 1698, 632, 7708, 7993, 1003, 1372, 5747, 2, 7, 5840, 5408, 11, 7200, 120, 4682, 7, 2, 3368, 2103, 8, 1140, 2, 880, 1692, 7, 68, 205, 3565, 5903, 21, 3204, 1372, 2, 2, 1098, 125, 128, 2429, 21, 9000, 2, 632, 2, 245, 39, 3526, 5, 9386, 2690, 6, 4951, 7, 2, 496, 90, 103, 316, 47, 348, 56, 2, 483, 2, 2865, 56, 6, 9739, 445, 9236, 2568, 2464, 8, 632, 29, 57, 1207, 1085, 17, 6, 3842, 632, 3055, 8, 516, 5765, 2, 88, 240, 128, 74, 15, 7906, 700, 2143, 109, 166, 642, 2, 5, 6358, 795, 7771, 6474, 2, 11, 1526, 4041, 2, 2, 2, 2, 2, 31, 160, 143, 6, 201, 7, 3404, 5, 85, 1748, 2, 15, 62, 516, 6, 2691, 6945, 132, 2, 4193, 7, 1056, 6756, 4262, 19, 164, 21, 2, 2, 1141, 281, 5, 4, 4461, 7, 5681, 2, 5, 1175, 2, 2628, 7232, 772, 447, 2066, 588, 17, 8508, 18, 5580, 2, 10, 10, 13, 100, 140, 23, 21, 14, 9, 43, 2, 48, 335, 120, 4, 559, 7, 3917, 5, 24, 581, 11, 9484, 3231, 225, 242, 164, 133, 18, 25, 2, 195, 45, 24, 99, 230, 125, 7, 2291, 18, 3783, 102, 38, 2, 32, 207, 398, 48, 25, 191, 79, 195, 7, 4, 512]\t[1, 2, 2, 2, 2, 9, 4, 86, 6594, 20, 7, 1300, 2, 6457, 5, 1238, 9, 24, 44, 2, 2, 2, 42, 2, 12, 9, 1004, 6, 55, 338, 1830, 11, 6, 2, 11, 6327, 121, 4, 2, 26, 3276, 2, 2, 2, 5233, 372, 4780, 13, 81, 24, 124, 4, 282, 138, 6457, 6546, 14, 1579, 756, 5, 2776, 8, 276, 2511, 21, 849, 36, 26, 55, 619, 537, 49, 7, 98, 483, 2244, 13, 1276, 40, 4, 1301, 65, 7, 4, 430, 5, 27, 336, 15, 925, 19, 6, 313, 7, 68, 205, 5, 2171, 34, 98, 4, 65, 7, 4, 3000, 430, 15, 2251, 29, 7446, 6, 1374, 4, 65, 7, 4, 132, 15, 5245, 677, 476, 17, 48, 36, 71, 68, 205, 3197, 5, 2847, 5, 4, 65, 7, 4, 185, 255, 5233, 34, 41, 2, 61, 2302, 9, 3020, 10, 10, 425, 3829, 2, 475, 1604, 2, 5438, 2, 2, 475, 4, 96, 7, 4, 113]\n",
            "訓練ラベル\t(25000,)\tint64\t1\t0\n",
            "テストデータ\t(25000,)\tobject\t[1, 9927, 2, 9, 6, 686, 19, 6, 117, 1056, 37, 1388, 4007, 5, 27, 1410, 33, 4, 1450, 568, 2550, 9, 6, 2, 37, 694, 15, 60, 4, 568, 461, 5525, 42, 303, 2523, 15, 9, 51, 4, 22, 9, 32, 44, 5, 6, 6823, 4565, 33, 4, 273, 10, 10, 7184, 2, 961, 4, 1347, 39, 1172, 2, 5274, 90, 5, 1525, 90, 429, 107, 1211, 493, 37, 26, 103, 90, 88, 29, 562, 2, 5311, 278, 137, 9365, 460, 562, 2, 250, 464, 5, 317, 90, 55, 76, 584, 18, 677, 153, 11, 2829, 7184, 5, 2, 169, 6, 840, 132, 2, 2, 6, 1138, 568, 1909, 5, 6437, 37, 2013, 6, 2513, 5379, 34, 1205, 318, 508, 93, 2, 83, 6, 2944, 6, 404, 1347, 5, 2, 21, 36, 28, 8, 2225, 4, 2, 5, 50, 9, 9927, 11, 4, 217, 7, 6, 2, 11, 5659, 4, 4246, 2, 620, 8, 339, 257, 85, 36, 26, 324, 34, 4, 1132, 1715, 9927, 5, 27, 117, 8960, 10, 10, 12, 562, 2, 891, 153, 29, 560, 8, 97, 6, 4565, 22, 103, 29, 1196, 8, 79, 6, 3484, 18, 2, 1040, 4, 881, 5, 814, 11, 4, 1226, 7, 2323, 5, 11, 1450, 7, 2, 4, 87, 2, 9, 17, 644, 4, 1524, 7777, 12, 9, 4, 31, 159, 236, 431, 7, 37, 1131, 103, 160, 22, 19, 2, 11, 4506, 10, 10, 2, 165, 473, 2, 305, 7, 29, 161, 40, 15, 1122, 33, 32, 21, 2, 9, 35, 321, 9489, 5, 408, 375, 8, 4, 91, 1078, 239, 21, 330, 25, 2, 3628, 15, 9, 35, 2, 284, 6, 680, 109, 55, 2, 5, 427, 1167, 23, 6, 785, 270, 2, 161, 40, 90, 33, 32, 5, 161, 181, 8, 157, 19, 90, 126, 174, 10, 10, 2, 9, 355, 202, 4, 91, 4764, 109, 11, 4, 1282, 7, 24, 38, 111, 221, 105, 25, 70, 67, 51, 29, 9, 547, 112, 4382, 34, 9927, 5, 27, 117, 1824, 1056, 5, 32, 4, 2515, 7, 2323, 11, 3441, 4609, 6, 1358, 284, 10, 10, 82, 2, 37, 2116, 245, 491, 8, 4, 58, 7, 4, 1423, 29, 82, 16, 24, 86, 1099, 21, 407, 6, 87, 7596, 29, 2938, 4, 4988, 7, 6, 2610, 2243, 143, 4, 226, 22, 5, 214, 11, 4, 130, 27, 580, 8, 413, 2523, 280, 53, 10, 10, 2, 47, 5978, 33, 314, 4, 8572, 2022, 19, 6, 5317, 5, 6, 2, 21, 9692, 853, 6, 1112, 324, 54, 29, 892, 2, 4, 86, 58, 75, 460, 124, 15, 4, 4537, 2, 47, 6, 4376, 2779, 439, 103, 4, 4565, 2, 2, 8, 193, 27, 173, 7, 4, 2, 5, 4899, 8, 2, 37, 272, 56, 8, 90, 15, 29, 64, 188, 83, 4, 767, 4246, 88, 29, 473, 8, 193, 1060, 23, 4, 5818, 7, 27, 6139, 2, 152, 1277, 51, 29, 817, 4, 311, 9706, 260, 110, 2, 11, 6, 87, 136, 11, 27, 2368, 313, 997, 2, 1726, 2373, 15, 216, 46, 7, 4, 6139, 5, 1274, 90, 33, 15, 58, 6, 55, 1281, 136, 31, 9706, 6, 196, 58, 103, 13, 2134, 12, 16, 126, 38, 878, 8, 2, 5, 1504, 15, 538, 33, 6, 58, 57, 31, 3792, 4, 582, 504, 7, 3536, 20, 231, 87, 6106, 54, 498, 16, 93, 34, 508, 10, 10, 75, 252, 80, 377, 6, 1051, 40, 4, 156, 131, 12, 186, 60, 103, 9633, 153, 14, 31, 2677, 4, 329, 1063, 7, 4, 1446, 3106, 7, 2, 51, 9, 355, 19, 12, 13, 244, 1595, 31, 152, 193, 76, 602, 11, 148, 289, 156, 800, 289, 2819, 5, 68, 568, 2243, 75, 850, 99, 117, 44, 7184, 5, 27, 3610, 457, 153, 245, 39, 27, 307, 250, 2247, 2, 9, 131, 6, 87, 6437, 21, 51, 93, 90, 413, 6, 2779, 132, 19, 163, 2373, 11, 27, 6139, 2, 1421, 17, 48, 29, 9, 11, 35, 908, 1154, 7, 4, 2, 9, 4, 132, 11, 4, 2, 7, 298, 519, 5, 3559, 728, 5, 9927, 9, 2, 8, 168, 33, 6, 87, 284, 33, 4, 1289, 7, 27, 113, 21, 89, 100, 29, 126, 869, 824, 15, 32, 26, 2523, 10, 10, 11, 35, 2704, 2, 1630, 15, 50, 9, 57, 255, 11, 4, 22, 24, 11, 4, 55, 767, 4246, 21, 13, 377, 73, 15, 9104, 52, 267, 668, 2247, 19, 57, 705, 611, 75, 26, 11, 4, 2226, 50, 11, 192, 5160, 6, 255, 39, 4, 1445, 7, 35, 154, 2, 1658, 164, 5, 2371, 1364, 8, 4, 1312, 8, 1632, 8, 4, 544, 7, 41, 154, 1461, 2, 2, 122, 142, 40, 15, 158, 153, 908, 14, 58, 2, 16, 940, 73, 224, 10, 10, 4, 767, 47, 434, 1283, 6, 171, 21, 24, 111, 2, 5786, 8, 22, 479, 4, 4565, 33, 273, 5, 594, 3985, 4, 5818, 7, 4, 6139, 5, 6518, 11, 428, 6207, 5, 2918, 27, 2, 3398, 638, 6, 6850, 15, 9, 99, 117, 18, 6, 87, 2112, 5, 4565, 20, 21, 4, 2, 234, 115, 2696, 25, 5, 12, 9, 6, 500, 23, 6, 312, 651, 5, 50, 26, 242, 49, 3908, 25, 850, 54, 25, 67, 4, 22, 120, 5, 120, 174, 600, 7, 4, 3908, 9, 15, 75, 26, 32, 2523, 5, 4, 522, 2, 2, 9, 82, 2561, 10, 10, 488]\t[1, 2, 2, 2, 2, 4, 2, 393, 7, 6, 2, 1830, 39, 998, 2445, 1364, 656, 94, 58, 143, 4, 454, 17, 12, 144, 366, 75, 6050, 39, 2, 21, 5610, 1915, 5, 1398, 83, 2, 7, 1306, 5, 6, 483, 5564, 3411, 44, 4, 394, 2, 7, 2, 10, 10, 2, 7279, 5, 2, 638, 4, 8921, 2, 5096, 4, 330, 5, 2, 4, 529, 14, 9521, 370, 157, 9, 2, 11, 6, 2, 109, 37, 9, 1305, 4, 9824, 2, 27, 292, 33, 4, 8465, 1923, 5, 1200, 27, 223, 8, 605, 2, 95, 2, 174, 5, 3582, 8, 4, 5315, 1946, 7, 27, 430, 351, 10, 10, 6, 2, 154, 255, 2, 23, 41, 658, 5, 6, 185, 430, 1442, 154, 183, 413, 162, 5, 162, 183, 783, 469, 9, 4, 8921, 2, 17, 594, 8559, 17, 4, 479, 7, 438]\n",
            "テストラベル\t(25000,)\tint64\t1\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1mXh9FCpi0Z",
        "colab_type": "text"
      },
      "source": [
        "よさそうに思いきや、データの内容が、object型でした。このままではだめそうですね。\n",
        "\n",
        "訓練ラベルは、整数型で1と0の値しかないため、このままでよさそうです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC34sWl9qAul",
        "colab_type": "text"
      },
      "source": [
        "### データ内容を確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PK89X_wqDol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e759ae4f-e212-4fb0-a691-e0c0cf5edac8"
      },
      "source": [
        "# 訓練データ内容を表示する\n",
        "train_data[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY9bLDzSqplE",
        "colab_type": "text"
      },
      "source": [
        "入力はテキストデータのはずなのに、数字の列になっています。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY47T28drusX",
        "colab_type": "text"
      },
      "source": [
        "### テキストデータの前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Qdt6AQrx4w",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "No | 処理     | 内容 | 例(This movie was just brilliant casting)\n",
        "---|----------|------|---\n",
        "1  | Tokenize | テキストを単語に区切る | `[\"This\", \"movie\", \"was\", \"just\", \"brilliant\", \"casting\"]`\n",
        "2  | Normarize| 大文字を小文字に変換、活用形を原型に変えるなど | `[\"this\", \"movie\", \"was\", \"just\", \"brilliant\", \"casting\"]`\n",
        "3  | Indexing | 単語の辞書を作成しながらインデックスに変換 | `[14, 22, 16, 43, 530, 13, 19]`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiKIi3L9uq-q",
        "colab_type": "text"
      },
      "source": [
        "テキストデータを扱うときは、各単語を単語のインデックスデータに変換して扱います。\n",
        "\n",
        "まず、テキストを、単語に区切ります。これが、データの最小単位になります。\n",
        "次に、正規化を行います。大文字を小文字に変換したり、活用形を原型に戻したり(played -> play)します。この処理は、実施するデータによって何を行うかまちまちです。\n",
        "次に、単語の辞書を作成しながらインデックスに変換していきます。\"this\"はインデックス14に変換するといった辞書を作成していき、同じ単語は同じインデックス番号となるようにします。\n",
        "\n",
        "このような処理によって単語インデックスのシーケンスができます。\n",
        "\n",
        "この imdb データセットでは、あらかじめ、テキストデータをインデックスデータに変換してくれています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5a5SRgwfgs",
        "colab_type": "text"
      },
      "source": [
        "### 単語インデックスデータをテキストに戻してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paMXCb5yw1ZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "970d064a-db5e-40d0-f8c1-249e53ab5a76"
      },
      "source": [
        "# 単語インデックス(単語->インデックス))を　逆転させる(インデックス -> 単語 )\n",
        "reverse_word_index = dict([(value, key) for (key, value) in imdb.get_word_index().items()])\n",
        "# imdbデータセットではインデックスオフセットは 3\n",
        "# 0: パディング用に予約, 1: シーケンス開始を示す, 2: 足きりして知らない単語用.\n",
        "decoded = []\n",
        "for i in train_data[0]:\n",
        "    if i == 0:\n",
        "        decoded.add(\"[PAD]\")\n",
        "    if i == 1:\n",
        "        decoded.add(\"[START]\")\n",
        "    if i == 2:\n",
        "        decoded.add(\"[UNK]\")\n",
        "    if i\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "decoded_review"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssULCBLvytV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}